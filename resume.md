---
header-includes:
  - \usepackage{geometry}
  - \geometry{a4paper, total={170mm,257mm}, left=10mm, right=10mm, top=10mm, bottom=10mm}
  - \usepackage[scaled]{helvet}
  - \renewcommand*\familydefault{\sfdefault}
  - \linespread{1.15}
---

```{=latex}
\begin{center}
```
# KARTHIK GANESAN
Motivated, cross-functional developer seeking full-time opportunity.   
  [LinkedIn](https://www.linkedin.com/in/karthik-ganesan-541488148/) |
  [Personal Website](https://www.karthikganesan.dev) |
  [GitHub](https://github.com/karthikgk97)  
  [karthik.gk97@gmail.com](mailto:karthik.gk97@gmail.com) | 480-692-0848

```{=latex}
\end{center}
```

## Education:
**Master of Science** \hfill <i> Aug' 18 – May' 20 </i> </span>  
<i>Arizona State University, USA </i> \hfill <i> GPA: 3.96 / 4 </i> </span>  
**Bachelor of Engineering** \hfill <i> Aug’ 14 – May’ 18 </i> </span>  
<i>Anna University, India  </i> \hfill <i> GPA: 8.03 / 10 </i> </span>

## Skills:
**Programming**: Python, Go, Java, C++, Rust, SQL, Terraform, HTML, CSS, Javascript, Bash, Matlab.  
**Framework and Tools**: Langchain, FastAPI, React, Streamlit, Docker, Git, Robot Operating System (ROS), Blender, OpenCV, Qt Designer, Selenium, Nvidia Omniverse  
**Cloud Platforms**: Google Cloud Platform (GCP), Amazon Web Services (AWS).

## Experience:
**Senior Developer** | Tyson Foods, Springdale, AR | Nov '23 - Present
<ul>
- Leading Tyson's Generative AI initiatives and development of an in-house chatbot powered by LLM. Built a FastAPI backend and assisted with the React frontend enabling natural language queries on Tyson Data. Deployed the chatbot securely and scalably on GCP using CloudRun, Load Balancer, and Identity-Aware Proxy (IAP).
- Developed and maintain versatile Python library with RESTful API server for agent construction, RAG techniques, keyword & semantic search, and LLM handling, driving Tyson's LLM applications.
- Implemented video rendering and custom file/image upload support in React frontend, integrating with backend server for advanced chunking, hybrid search-based retrieval in RAG applications and LLM interaction.
</ul>

**Developer** | Tyson Foods, Springdale, AR | Nov '21 - Nov '23
<ul>
- Engineered an LLM application using Prompt Engineering and RAG approach through Hybrid Search (Semantic + Keyword) for natural language querying of structured data, providing real-time visualizations and persistent chat history, reducing PowerBI report interaction time by 70%
- Implemented simulation-based workflow using Nvidia Omniverse, ROS2, MoveIt2, AWS, and Reinforcement Learning for digital twin feasibility testing
- Developed ML models on AWS Sagemaker for synthetic image detection, achieving 70% accuracy across 5 classes (97% max class accuracy) while reducing training time by 50% through Transfer Learning Twice and Distributed Training
- Architected cloud-based pipeline for synthetic data generation using AWS, Python, Blender, Docker, and Terraform, implementing CI/CD for accelerated streamlined development cycles
</ul>

**Software Application Engineer** | Duke University, Durham, NC | Jan’ 21 – Oct’ 21
<ul>
- Led the development of a high-performance Optical Coherence Tomography (OCT) data-acquisition and processing software application using Python and Qt Designer.
- Established and maintained an efficient Project Management System leveraging Jira and Confluence, ensuring seamless documentation and user request management.
- Collaborated with stakeholders to define software requirements for OCT, assessing feasibility and aligning with project goals.
- Enhanced existing projects by resolving bugs, implementing requested features, and delivering comprehensive documentation using Qt Designer, C++, Jira, and Git.
</ul>  

**Robotics Research Assistant** | Arizona State University, Tempe, AZ | Jan’20 – Jan’ 21
<ul>
- Engineered an autonomous vehicular robot and its middleware using ROS and C++ for real-world operation.
- Integrated the robot into Gazebo simulation environment using URDF, concurrently developing a user-friendly GUI with Qt Designer and Python to access camera sensor data.
- Applied YOLOv3 model to create a highly accurate ML model, achieving a 90% detection accuracy for custom objects, enhancing the robot's navigation capabilities.
</ul>
