---
header-includes:
  - \usepackage{geometry}
  - \geometry{a4paper, total={170mm,257mm}, left=20mm, top=20mm}
  - \usepackage[scaled]{helvet}
  - \renewcommand*\familydefault{\sfdefault}
---

```{=latex}
\begin{center}
```

  <h3>KARTHIK GANESAN</h3>
Motivated, cross-functional developer seeking full-time opportunity.   
  [LinkedIn](https://www.linkedin.com/in/karthik-ganesan-541488148/) |
  [Personal Website](https://www.karthikganesan.dev) |
  [GitHub](https://github.com/karthikgk97)  
  [karthik.gk97@gmail.com](mailto:karthik.gk97@gmail.com) | 480-692-0848

```{=latex}
\end{center}
```

## Education:
**Master of Science** \hfill <i> Aug' 18 – May' 20 </i> </span>  
<i>Arizona State University, USA </i> \hfill <i> GPA: 3.96 / 4 </i> </span>  
**Bachelor of Engineering** \hfill <i> Aug’ 14 – May’ 18 </i> </span>  
<i>Anna University, India  </i> \hfill <i> GPA: 8.03 / 10 </i> </span>

## Skills:
**Technical**: Python, Rust, C++, SQL, Terraform, HTML, CSS, React, Bash, Matlab.  
**Framework and Tools**: Langchain, Streamlit, Docker, Git, ROS, Blender, OpenCV, Qt Designer, Selenium, Power BI, Nvidia Omniverse  
**Cloud Platforms**: GCP, AWS.  
**Proficiencies**: Data Structures, Algorithms, CI/CD, Robotics, AI/ML, Simulation, LLM.

## Experience:
**Developer** | Tyson Foods, Springdale, AR | Nov '21 - Present
<ul>
- Leading Tyson's Language Model (LLM) initiatives, developed a streamlined chat interface using LLM and Streamlit. Optimizes SQL query writing and execution with GCP Big Query client. Deployed securely on GCP's Cloud Run, GCR, load balancer, and Identity-Aware Proxy, emphasizing structured data interaction through natural language queries.
- Engineered an asynchronous Python library for Tyson, enabling the efficient reading and processing of BigQuery data. This library also facilitates the creation of embeddings and stores them in ChromaDB/QdrantDB on GCP CloudRun, with mounted GCP Filestore for high-speed I/O.
- Established a simulation-based workflow at Tyson for rapid prototyping of LLM applications using Nvidia Omniverse, ROS2, MoveIt2, AWS, and Reinforcement Learning. Conducted feasibility testing of digital twin and implemented RL in simulation.
-  Developed ML models with AWS Sagemaker, MxNET, PyTorch & TensorFlow, evaluating synthetic image detection performance. Achieved a 50% reduction in training time through techniques like Transfer Learning Twice and Distributed Training, achieving an accuracy of approximately 70% across 5 classes, with a max class accuracy of 97%.
- Architected and developed a cloud-based pipeline using AWS and Blender-Python for synthetic data generation. Leveraged AWS Batch, Lambda, S3, ECR, Python, Blender, Docker, Terraform, and GitLab CI for streamlined development.
- Crafted comprehensive "Press Release and Frequently Asked Question" (PRFAQ) documents, encompassing project requirements, high-level system design diagrams, milestones, and Return on Investments (ROIs).
</ul>

**Software Application Engineer** | Duke University, Durham, NC | Jan’ 21 – Oct’ 21
<ul>
- Led the development of a high-performance Optical Coherence Tomography (OCT) data-acquisition and processing software application using Python and Qt Designer.
- Established and maintained an efficient Project Management System leveraging Jira and Confluence, ensuring seamless documentation and user request management.
- Collaborated with stakeholders to define software requirements for OCT, assessing feasibility and aligning with project goals.
- Enhanced existing projects by resolving bugs, implementing requested features, and delivering comprehensive documentation using Qt Designer, C++, Jira, and Git.
</ul>  

**Robotics Research Assistant** | Arizona State University, Tempe, AZ | Jan’20 – Jan’ 21
<ul>
- Engineered an autonomous vehicular robot and its middleware using ROS and C++ for real-world operation.
- Integrated the robot into Gazebo simulation environment using URDF, concurrently developing a user-friendly GUI with Qt Designer and Python to access camera sensor data.
- Applied YOLOv3 model to create a highly accurate ML model, achieving a 90% detection accuracy for custom objects, enhancing the robot's navigation capabilities.
</ul>
